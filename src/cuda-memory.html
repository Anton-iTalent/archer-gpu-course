<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

<title>Memory</title>

  <link rel="stylesheet" href="../dist/reset.css">
  <link rel="stylesheet" href="../dist/reveal.css">
  <link rel="stylesheet" href="../dist/theme/white.css">
  <link rel="stylesheet" href="../css/local.css">

  <!--- Theme used for syntax highlighted code --->
  <link rel="stylesheet" href="../plugin/highlight/vs.css">

</head>

<!-- Start of presentation --> 
<body>
<div class="reveal">
<div class="slides">

  <section>

    <h1 style = "text-transform: none !important"> More on Memory </h1>

    <br>
    <p>Material by: Kevin Stratford </p>
    <img class = "plain" src ="../img/epcc_logo.png" alt = "EPCC Logo" />

  </section>

  <section>

    <h4> CUDA Memory so far...</h4>

    <p style = "text-align: left;">
      Global memory:
    </p> 
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
      <li> Allocated on host</li>
      <li> Available to both host and device read/write </li>
    </ul>

    <p style = "text-align: left; padding-top: 10px;">
    Local variables in kernels
    </p>
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
       <li> Private on a per thread basis
       <li> Usually expected to be held in registers </li>
    </ul>
    </ul>
  </section>

  <section>

    <h4> Other types of memory </h4>

    <p style = "text-align: left;">
      Managed memory:
    </p> 
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
       <li> Unified address space: available on host and device </li>
       <li> No explicit copies required </li>
       <li> Very useful for development / more complex code </li>
    </ul>

    <p style = "text-align: left;">
      Shared memory:
    </p> 
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
       <li> Shared between threads in the same block</li>
       <li> Often declared statically in the kernel (can be dynamic)
       <li> Lifetime of the kernel
    </ul>

    <p style = "text-align: left;">
    Constant cache memory:
    </p> 
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
       <li> Read only in kernel</li>
       <li> No cache coherency mechanism required to support writes
       <li> Fast and effectively very high bandwidth 
    </ul>

  </section>


  <section>

    <h4> Host and device memory </h4>

    <p>
    <pre class = "stretch"><code class = "cpp" data-trim>

    /* Schematically */

    /* Allocate and initialise host memory ... */

    h_ptr = malloc(nbytes);
    ...

    /* Allocate device memory and copy */

    cudaMalloc(&d_ptr, nbytes)
    cudaMemcpy(d_ptr, h_ptr, nbytes, cudaMemCpyHostToDevice);
    ...

    /* Use device memory in kernel */
    kernel<<<...>>> (d_ptr, ...)

    </code></pre>

  </section>

   <section>
    <h4> Unified memory </h4>


    <p>
    <pre class = "stretch"><code class = "cpp" data-trim data-noescape>

  /* Can we do both? */

  <p class = "fragment" style ="font-size: 100%; margin: 0px;">
  cudaMallocManaged(&ptr, nbytes);</p>

  /* Initialise data on host */
  for (i = 0; i < NDATA; i++) {
    ptr[i] = value;
  }

  /* Use data in kernel */
  kernel<<<...>>> (ptr, ...)

  /* ... and get results back */

    </code></pre>

  </section>

    <section>
    <h4> Managed memory</h4>

    <p style = "font-size:60%">
    <code class = "cpp">
    __host__ cudaErr_t cudaMallocManaged(void ** dptr, int sz);
    </code>
    </p>

    <p style = "text-align: left;">
    Allocated on the host
    </p>
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
       <li> ...but single address space for host and device </li>
       <li> Management of copies performed by CUDA runtime </li>
       <li> Release with <code>cudaFree()</code> </li>
    </ul>
    
    <p style = "text-align: left;">
    Page migration
    </p>
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
       <li> Access to memory not present generates <i>page fault</i></li>
       <li>  Pages are then copied; page size may be e.g., 64KB </li>
       <li>  Costs time, so can be slow relative to <code>cudaMemcpy()</code></li>
       <li> Can specify prefetches, or provide hints </li>
    </ul>

    </ul>
    </p>

  </section>

 <section>
    <h4> Managed memory (cont..)</h4>

    <p>
    <pre class = "stretch"><code class = "cpp" data-trim data-noescape>

    /* Prefetch to destination device */

    cudaGetDevice(&device)
    cudaMallocManaged(&ptr, nbytes);
    ...
    cudaMemPrefetchAsync(ptr, nbytes, device, NULL);
    ...

    /* Hints */

    cudaMemAdvise(ptr, nbytes, advice, device);

    /* advice: cudaMemAdviseSetReadMostly */
    /*         cudaMemAdviseSetPreferredLocation */
    /*         cudaMemAdviseSetAccessedBy */

    </code></pre>
    </p>

  </section>

  <section>

    <h4> Shared memory </h4>

    <p style = "text-align: left;">
    Accessible by more than one thread.
    </p>


    <p style = "text-align: left;">
    E.g., global memory (shared between all threads)
    </p>

    <pre><code class = "cpp" data-trim data-noescape>
    __global__ void kernel(double * a) {

      int tid = threadIdx.x; /* Local variable (register) */

      a[tid] = 0.0;          /* a[] (global) */
      ...
    </code></pre>


  </section>

  <section>
    <h4> Updates to shared memory </h4>

    <p style = "text-align: left;;">
    Consider the following kernel code:
    </p>  

    <pre><code class = "cpp" data-trim data-noescape>
    /* Variable a is in global memory */
    /* All threads ... */

    a[0] = a[0] + 1;
    </code></pre>

    <p style = "text-align: left;">
    What is really happening on each individual thread?
    </p>  

  </section>

  <section>
    <h4> Avoid race conditions </h4>

    <p style = "text-align: left;">
      Requires an <i>atomic</i> operation.
    </p>

    <pre><code class = "cpp" data-trim data-noescape>
    /* Variable n is in global memory */
    /* All threads ... */

    atomicAdd(&n, 1);
    </code></pre>

    <p style = "text-align: left;">
      Separate operations are conbined in a single entity on any thread:
    </p>
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
      <li> Obtain lock on memory location </li>
      <li> Read value to register and add relevant increment (1 here) </li>
      <li> Write result back to the same global memory location </li>
      <li> Release the lock on the memory location </li>
    </ul>

    <p style = "text-align: left;">
    In general: updates to shared memory may need synchronisation
    </p>

  </section>

  <section>

    <h4> <code>__shared__</code> qualifier </h4>

    <p style = "text-align: left; padding-top: 10px;">
    Within a kernel, e.g.,:
    </p>

    <pre><code class = "cpp" data-trim data-noescape>
     __shared__ double tmp[NTHREADS_PER_BLOCK];
    </code></pre>

    <p style = "text-align: left; padding-top: 10px;">
    Shared only between threads in the same block
    </p>
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
       <li> Useful for temporary values, particularly if significant reuse
       <li> Marshalling data within a block
       <li> May be used to perform reductions (sum, min, max)
    </ul>

    <p style = "text-align: left; padding-top: 10px;">
    Caveats
    </p>
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
      <li> May require synchronistations
      <li> Limited resource, e.g., 50 kB per block
    </ul>

  </section>

  <section>
    <h4> Synchronisation </h4>

    <p style = "text-align: left; padding-top: 10px;">
    Basic synchroniation via <code>__syncthreads()</code>
    </p>
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
      <li> All threads must arrive before any can continue
      <li> All threads in block must call (or deadlock)
    </ul>
    <p style = "text-align: left; padding-top: 10px;">
    Many other intrinsics perform variations on theme
    </p>
    
  </section>
  
  <section>
    <h4> Example: Reverse elements in array </h4>


    <pre><code class = "cpp" data-trim data-noescape>
/* Reverse elements so that the order 0,1,2,3,...
 * becomes ...,3,2,1,0
 * Assume we have one block. */
</pre></code>

    <pre><code class = "cpp" data-trim data-noescape>
__global__ void reverseElements(int * myArray) {

  __shared__ int tmp[THREADS_PER_BLOCK];

  int idx = threadIdx.x;
  tmp[idx] = myArray[idx];
<p class = "fragment" style = "margin: 0em; font-size: 100%;">
  __syncthreads();
</p>
  myArray[THREADS_PER_BLOCK - (idx+1)] = tmp[idx];
}
    </code></pre>
  </section>

  <section>

    <h4> Constant memory </h4>

    <p style = "text-align: left;">
    E.g., variables passed by value to a kernel
    </p>

    <pre><code class = "cpp" data-trim data-noescape>
      __global__ void scale_vector(double a, double * x) {

      ...
      x[tid] = a*x[tid];      /* a appears in constant memory */
    </code></pre>

    <p style = "text-align: left;">
      Constant memory:
    </p> 
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
      <li> fast read-only cache available to all threads</li>
      <li> no updates so no cache coherencey required</li>
      <li> Limited resource 64kB total</li>
    </ul>
    
  </section>
    
  <section>
    <h4> Constant memory </h4>

    <p style = "text-align: left;">
    You may also see:
    </p> 

    <p>
    <pre class = "stretch"><code class = "cpp" data-trim>
  /* Variable declared at file scope with
   *  __constant__ memory space qualifier  */

  static __constant__ double coeffs[3];

  __host__ int main(int argc, char ** argv) {

    ...
    cudaMemcpyToSymbol(coeffs, values, 3*sizeof(double));
    ...
  }

  __global__ void kernel(...) {
    ...
    /* may reference coeffs[] */
  }
    </code></pre>

  </section>

  <section>
    <h4> Exercises </h4>

    <p style = "text-align: left;">
      Use of <code>__shared__</code> and atomic updates is important
    </p>
    <ul style = "display: block; float: left; width: 100%; padding-left: 20px; padding-bottom: 20px; font-size: 60%;">
      <li> Allows reductions</li>
    </ul>
  </section>

</div>
</div>

<!-- End of presentation -->

  <script src="../dist/reveal.js"></script>
  <script src="../plugin/notes/notes.js"></script>
  <script src="../plugin/markdown/markdown.js"></script>
  <script src="../plugin/highlight/highlight.js"></script>
  <script src="../plugin/math/math.js"></script>

  <script>
    // More info about initialization & config:
    // - https://revealjs.com/initialization/
    // - https://revealjs.com/config/
    Reveal.initialize({
        hash: true,
        controls: false,
        center: false,
        slideNumber: 'c/t',
        mathjax2: {
            mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js',
            config: 'TeX-AMS_HTML-full'},
        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [ RevealMarkdown, RevealHighlight, RevealNotes,
                   RevealMath.MathJax2],
    });
  </script>


</body>
</html>
